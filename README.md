# Level1_STS_01
A solution for STS Competition in the 4nd BoostCamp AI Tech by **ê°œë°œìƒˆë°œ(ğŸ•ğŸ¾ğŸ¥ğŸ¾) (1ì¡°)**  


## Role
- PM : ì´ìƒë¬¸ <br>
- Data : ì‹ í˜œì§„ <br>
- Research : ê¹€í•´ì› <br>
- Code review : ì–‘ë´‰ì„, ì„ì„±ê·¼ <br>


## Content
- [Competition Abstract](#competition-abstract)
- [Model](#model)
- [Preprocessing](#preprocessing)
- [Data augmentation](#data-augmentation)
- [Train](#train)
- [Inference](#inference)
- [Result](#result)


## Competition Abstract  
- **ì˜ë¯¸ ìœ ì‚¬ë„ íŒë³„(Semantic Text Similarity, STS)** ì´ë€ ë‘ ë¬¸ì¥ì´ ì˜ë¯¸ì ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ë¥¼ ìˆ˜ì¹˜í™”í•˜ëŠ” ìì—°ì–´ì²˜ë¦¬ íƒœìŠ¤í¬ì´ë‹¤.
- STS ë°ì´í„°ì…‹ì„ í™œìš©í•´ ë‘ ë¬¸ì¥ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ëŠ” AIëª¨ë¸ì„ êµ¬ì¶•í•œë‹¤. 
- 0ê³¼ 5ì‚¬ì´ì˜ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.
- ì´ ë°ì´í„° ê°œìˆ˜ : 10,974 ë¬¸ì¥ ìŒ
  - Train : 9,324
  - Test : 1,100
  - Dev : 550
  
## Project Tree
<pre>
<code>
level1_semantictextsimilarity_nlp-level1-nlp-01
â”œâ”€â”€ README.md
â”œâ”€â”€ code   
â”‚   â”œâ”€â”€ config
â”‚   â”‚   â””â”€â”€ base_config.yaml
â”‚   â”œâ”€â”€ data_loader
â”‚   â”‚   â””â”€â”€ data_loader.py
â”‚   â”œâ”€â”€ model
â”‚   â”‚   â””â”€â”€ model.py
â”‚   â”œâ”€â”€ utils
â”‚   â”‚   â”œâ”€â”€ prediction_analysis.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ saved 
â”‚   â”‚   â””â”€â”€ ... # model & submission.csv saved here
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ DA.png
â”‚   â”œâ”€â”€ EDA.ipynb
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ dev.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â”œâ”€â”€ sample_submission.csv
â”‚   â”œâ”€â”€ preprocessed 
â”‚   â”‚   â””â”€â”€ ... # Store preprocessed data
â””â”€â”€ install.sh
</code>
</pre>

## Model

|Model|huggingface_model_name|github|
|:---|:---|:---|
| KLUE-RoBERTa-large | klue/roberta-large | https://github.com/KLUE-benchmark/KLUE |
| TUNiB-Electra-ko-base | tunib/electra-ko-base | https://github.com/tunib-ai/tunib-electra |
| KoELECTRA-base-v3 | monologg/koelectra-base-v3-discriminator | https://github.com/monologg/KoELECTRA/blob/master/README_EN.md |<br>


## Preprocessing
ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰í•©ë‹ˆë‹¤.
```
python code/preprocessing.py
```
ì´ ëª¨ë“ˆì„ í†µí•´ ì´ëª¨ì§€ ì œê±°, ë§ì¶¤ë²• êµì •ì„, text normalizingì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ì¶¤ë²• êµì •ì€ py-hanspell(https://github.com/ssut/py-hanspell)ì„ ì‚¬ìš©í•˜ê³ , text normaliziingì€ soynlp(https://github.com/lovit/soynlp)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.


## Data augmentation
```
## TODO: augmentation ì½”ë“œ ë„£ê¸°
```  


## Train
í•™ìŠµì€ ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰í•©ë‹ˆë‹¤.  

**1. config íŒŒì¼ ë§Œë“¤ê¸°**  
`./code/config/base_config.yaml` íŒŒì¼ì˜ ì–‘ì‹ê³¼ ê°™ì´ í•™ìŠµ ë°ì´í„°, ì‚¬ìš©í•  ëª¨ë¸, hyperparameter, wandb log ì£¼ì†Œ ë“±ì„ ì§€ì •í•´ ì¤€ `my_config.yaml` íŒŒì¼ì„ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. 

**2. í•™ìŠµ ìˆ˜í–‰**  
í„°ë¯¸ë„ ì°½ì— `python train.py --my_config`ì„ ì…ë ¥í•˜ì—¬ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. config íŒŒì¼ì— ì…ë ¥ëœ ì„¤ì •ìœ¼ë¡œ í•™ìŠµì´ ì§„í–‰ë©ë‹ˆë‹¤. í•™ìŠµì´ ëª¨ë‘ ì™„ë£Œë˜ë©´ dev setì— ëŒ€í•œ pearson correlation ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ì´ `./code/models/` ì— ì €ì¥ë©ë‹ˆë‹¤.  


## Inference
1. í•™ìŠµ ë•Œ ì‚¬ìš©í–ˆë˜ config íŒŒì¼ì„ `inference.py`ì— ì¸ìë¡œ ë„£ì–´ì„œ ì¶”ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤.  
`python code/inference.py --config my_config`
2. config íŒŒì¼ì˜ `Inference` ì„¸íŒ…ì„ ì´ìš©í•˜ë©´ ì—¬ëŸ¬ ëª¨ë¸ë¼ë¦¬ì˜ ensembleë„ ìˆ˜í–‰í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  


## Result
||Pearson|Rank|
|:---|:---|:---|
|Public|0.9271|7|
|**Private**|**0.9337**|**5**|
